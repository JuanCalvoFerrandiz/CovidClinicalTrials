{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clinical Trials.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmL-aEI7rwe5",
        "colab_type": "text"
      },
      "source": [
        "We shall outline the process to work with clinical trials data to parse the XML file. This can be further extended to multiple use cases for other data as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xICzB_VU1XPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY9hrdjk1sr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting the imports done\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qmxoFmPseMh",
        "colab_type": "text"
      },
      "source": [
        "The XML file can be viewed as 'organized as a tree'. Fortunately, an inspection of a single XML file in several cases can help us know the root node, leaves, etc. which can be leveraged to extract key information. We have followed the exact same process here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ORgAJdEQjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utility function to parse our XML file\n",
        "def xml_csv_convert(xml_file):\n",
        "  tree = ET.parse(xml_file)\n",
        "  root = tree.getroot()\n",
        "  #The key columns that we want\n",
        "  title_text = \"\"\n",
        "  detailed_description = \"\"\n",
        "  summary = \"\"\n",
        "  fac_name = \"\"\n",
        "  fac_address = \"\"\n",
        "  status = \"\"\n",
        "  source = \"\"\n",
        "\n",
        "  for desc in root.iter(\"detailed_description\"):\n",
        "    for txt in desc.findall('textblock'):\n",
        "      detailed_desc = txt.text\n",
        "      detailed_desc = detailed_desc.replace('\\n','')\n",
        "      detailed_desc = detailed_desc.replace(';',',')\n",
        "      detailed_desc=re.sub(' +',' ',detailed_desc)\n",
        "      detailed_description = detailed_desc\n",
        "  for summ in root.iter(\"brief_summary\"):\n",
        "    for txt in summ.findall('textblock'):\n",
        "      summary_text = txt.text\n",
        "      summary_text = summary_text.replace('\\n','')\n",
        "      summary_text = summary_text.replace(';',',')\n",
        "      summary_text=re.sub(' +',' ',summary_text)\n",
        "      summary = summary_text\n",
        "\n",
        "  for title in root.iter(\"official_title\"):\n",
        "    title_text = title.text\n",
        "  for loc in root.iter(\"facility\"):\n",
        "    for t in loc.findall('name'):\n",
        "      fac_name = t.text\n",
        "    for ad in loc.findall('address'):\n",
        "      fac_address = ad.find('city').text+\", \"+ad.find('country').text\n",
        "  for stat in root.iter(\"overall_status\"):\n",
        "    status = stat.text\n",
        "  for sr in root.iter(\"source\"):\n",
        "    source = sr.text\n",
        "  #Creating a string in the correct format to write to the CSV. Note that we are using a semicolon delimiter  \n",
        "  total_text = \"\\\"\" +title_text+\"\\\"\" +\";\"+\"\\\"\"+summary +\"\\\"\"+ \";\" + \"\\\"\" + detailed_description + \"\\\"\" + \";\" + \"\\\"\" + fac_name + \"\\\"\" + \";\" + \"\\\"\" + fac_address + \"\\\"\" + \";\" + \"\\\"\" + status + \"\\\"\" + \";\" + \"\\\"\" + source + \"\\\"\"\n",
        "  return total_text\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBcXnvmmtb-J",
        "colab_type": "text"
      },
      "source": [
        "The XML files are separate for each clinical trial so we need to iterate over each of the XML files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjrUKM2oU_Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import csv\n",
        "subdir = '/content/gdrive/My Drive/search_result'\n",
        "with open('clinical_data.csv','w',encoding='utf-8') as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames = [\"title\", \"summary\", \"detailed_description\", \"facility_name\", \"facility_address\", \"status\", \"source\"], delimiter = \";\")\n",
        "  writer.writeheader()\n",
        "  for root,dir,files in os.walk('/content/gdrive/My Drive/search_result'):\n",
        "    for name in files:\n",
        "      print (xml_csv_convert(os.path.join(subdir,name)))\n",
        "      csvfile.write(xml_csv_convert(os.path.join(subdir,name)))\n",
        "      csvfile.write('\\n')\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
